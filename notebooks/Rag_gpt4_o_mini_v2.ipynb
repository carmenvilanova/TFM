{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB1uhiodVKSO",
        "outputId": "8ee7e3aa-bb67-477e-ae88-fa27f39761bd"
      },
      "outputs": [],
      "source": [
        "!pip install openpyxl\n",
        "!pip install pdfplumber\n",
        "!pip install -U langchain-community\n",
        "!pip install chromadb\n",
        "!pip install transformers accelerate datasets peft trl bitsandbytes\n",
        "!pip install langchain\n",
        "!pip install faiss-cpu\n",
        "!pip install -U sentence-transformers\n",
        "!pip install openai\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZkdLvF7VQk2"
      },
      "outputs": [],
      "source": [
        "# Importar librer√≠as\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import regex as re\n",
        "import datetime\n",
        "import time\n",
        "import openpyxl\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pdfplumber\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\n",
        "import torch\n",
        "from trl import SFTTrainer\n",
        "import gc\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import torch\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqD9XbIYVULF"
      },
      "outputs": [],
      "source": [
        "posibles_params = {\n",
        "    \"page\": 0,  # N√∫mero de p√°gina (empieza en 0)\n",
        "    \"pageSize\": 50,  # Tama√±o de p√°gina\n",
        "    \"order\": \"numeroConvocatoria\",  # Campo por el que ordenar\n",
        "    \"direccion\": \"asc\",  # Sentido de la ordenaci√≥n: 'asc' o 'desc'\n",
        "    \"vpd\": \"GE\",  # Identificador del portal\n",
        "    \"descripcion\": \"Resoluci√≥n\",  # Texto a buscar en el t√≠tulo o descripci√≥n\n",
        "    \"descripcionTipoBusqueda\": 0,  # 0: frase exacta, 1: todas las palabras, 2: alguna palabra\n",
        "    \"numeroConvocatoria\": \"376046\",  # C√≥digo BDNS a buscar\n",
        "    \"mrr\": False,  # Mecanismo de recuperaci√≥n y resiliencia\n",
        "    \"fechaDesde\": \"18/12/2017\",  # Fecha de inicio (dd/mm/yyyy)\n",
        "    \"fechaHasta\": \"18/12/2017\",  # Fecha de fin (dd/mm/yyyy)\n",
        "    \"tipoAdministracion\": \"C\",  # 'C', 'A', 'L', 'O'\n",
        "    \"organos\": [\"713\", \"4730\"],  # Lista de identificadores de √≥rganos administrativos\n",
        "    \"regiones\": [3, 50],  # Lista de identificadores de regiones\n",
        "    \"tiposBeneficiario\": [3],  # Lista de identificadores de tipos de beneficiarios\n",
        "    \"instrumentos\": [1],  # Lista de identificadores de instrumentos de ayuda\n",
        "    \"finalidad\": 11,  # Identificador de la finalidad de la pol√≠tica de gasto\n",
        "    \"ayudaEstado\": \"SA.45221\"  # C√≥digo de ayuda de estado\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKRtHpRdVdHO",
        "outputId": "5c97f130-bc84-4f00-f67e-f1583c93a2b0"
      },
      "outputs": [],
      "source": [
        "# Configuraci√≥n de par√°metros\n",
        "base_url = \"https://www.pap.hacienda.gob.es/bdnstrans/api/convocatorias/busqueda\"\n",
        "vpd = \"GE\"  # Identificador del portal, seg√∫n la docu\n",
        "page_size = 25\n",
        "max_paginas = 3  # Puedes aumentar si quieres m√°s resultados\n",
        "\n",
        "resultados = []\n",
        "\n",
        "\n",
        "# 2. Probar la API con par√°metros y cabecera Accept: application/json\n",
        "params = {\n",
        "    \"vpd\": vpd,\n",
        "    \"page\": 0,\n",
        "    \"pageSize\": page_size\n",
        "}\n",
        "headers = {\"Accept\": \"application/json\"}\n",
        "\n",
        "# Realizar una primera solicitud para verificar el Content-Type\n",
        "try:\n",
        "    r2 = requests.get(base_url, params=params, headers=headers)\n",
        "    r2.raise_for_status() # Lanza una excepci√≥n para errores HTTP (4xx o 5xx)\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"‚ùå Error al conectar con la API o respuesta inicial: {e}\")\n",
        "    exit() # Salir si la conexi√≥n inicial falla\n",
        "\n",
        "# 3. Si la respuesta es JSON, continuar con la descarga paginada\n",
        "if \"application/json\" in r2.headers.get(\"Content-Type\", \"\"):\n",
        "    print(\"‚úÖ La API responde con JSON. Descargando datos paginados...\")\n",
        "    for pagina in range(0, max_paginas):\n",
        "        print(f\"üìÑ Cargando p√°gina {pagina}...\")\n",
        "        params[\"page\"] = pagina\n",
        "        try:\n",
        "            response = requests.get(base_url, params=params, headers=headers)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "            convocatorias = data.get(\"convocatorias\", data.get(\"content\", []))  # content es com√∫n en APIs paginadas\n",
        "            if not convocatorias:\n",
        "                print(\"‚úÖ No hay m√°s datos.\")\n",
        "                break\n",
        "            resultados.extend(convocatorias)\n",
        "            time.sleep(0.5)  # para evitar sobrecargar la API\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error en la p√°gina {pagina}: {e}\")\n",
        "            break\n",
        "    # Convertir a DataFrame y mostrar\n",
        "    df = pd.DataFrame(resultados)\n",
        "    print(\"Columnas disponibles:\", df.columns.tolist())\n",
        "    # Mostrar las primeras columnas si existen\n",
        "    cols = [c for c in [\"id\", \"titulo\", \"organoConvocante\", \"fechaPublicacion\"] if c in df.columns]\n",
        "else:\n",
        "    print(\"‚ùå La API no responde con JSON. Revisa los par√°metros, la URL o si la API est√° disponible.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jwy5mGwbW6GK"
      },
      "outputs": [],
      "source": [
        "df.head(10)  # Mostrar las primeras filas del DataFrame\n",
        "\n",
        "# Guardar en un archivo Excel\n",
        "output_file = \"listado_convocatorias.xlsx\"\n",
        "df.to_excel(output_file, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "U7KaO2hSXBQS",
        "outputId": "cb97e61f-28da-47c8-cf23-2eeb1dee4891"
      },
      "outputs": [],
      "source": [
        "df.head(10)  # Mostrar las primeras filas del DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class get_convocatorias:\n",
        "    def __init__(self, param_grid, url, headers_grid ): \n",
        "        self.param_grid = param_grid\n",
        "        self.url = url\n",
        "        self.headers_grid = headers_grid\n",
        "        self.downloaded_convs_id = list()\n",
        "        self.error_convs = list()\n",
        "        self.txt_convs = {}\n",
        "        \n",
        "    def request_convocatorias(self, num_conv): \n",
        "    \n",
        "        self.param_grid[\"numConv\"] = num_conv\n",
        "        r = requests.get(self.url, params=self.param_grid, headers=self.headers_grid)\n",
        "    \n",
        "        if \"application/json\" in r.headers.get(\"Content-Type\", \"\"):\n",
        "            data = r.json()\n",
        "            # Si la respuesta es una lista, convi√©rtela directamente\n",
        "            if isinstance(data, list):\n",
        "                convocatoria = pd.DataFrame(data)\n",
        "            # Si es un dict, convi√©rtelo en DataFrame de una fila\n",
        "            elif isinstance(data, dict):\n",
        "                convocatoria = pd.DataFrame([data])\n",
        "            else:\n",
        "                print(\"Respuesta inesperada:\", data)\n",
        "                convocatoria = pd.DataFrame()\n",
        "            \n",
        "            #print(\"Columnas disponibles:\",convocatoria.columns.tolist())\n",
        "            self.downloaded_convs_id.append(num_conv)\n",
        "    \n",
        "        else:\n",
        "            print(f\"‚ùå La API no responde con JSON para la convocatorio {num_conv}. Revisa los par√°metros, la URL o si la API est√° disponible.\")\n",
        "            convocatoria = pd.DataFrame()\n",
        "            self.error_convs.append(num_conv)\n",
        "        \n",
        "        return convocatoria\n",
        "        \n",
        "    def download_convocatorias(self, dir_name, docs_list):\n",
        "        os.makedirs(dir_name, exist_ok=True)\n",
        "\n",
        "        for doc in docs_list:\n",
        "            id_doc = doc[0][0]['id']\n",
        "            nombre = doc.get('nombreFic', f\"documento_{id_doc}.pdf\")\n",
        "            url = f\"https://www.infosubvenciones.es/bdnstrans/api/convocatorias/documentos?idDocumento={id_doc}\"\n",
        "            print(f\"Descargando {nombre} ...\")\n",
        "            resp = requests.get(url)\n",
        "            if resp.status_code == 200:\n",
        "                with open(os.path.join(\"documentos_convocatoria\", nombre), \"wb\") as f:\n",
        "                    f.write(resp.content)\n",
        "                print(f\"‚úÖ Guardado: {nombre}\")\n",
        "            else:\n",
        "                print(f\"‚ùå Error al descargar {nombre} (status {resp.status_code})\")\n",
        "                \n",
        "    def pdf_to_txt(self, pdf_folder, output_name_root):\n",
        "        self.txt_convs = {}\n",
        "        for filename in os.listdir(pdf_folder):\n",
        "            if filename.endswith(\".pdf\"):\n",
        "                filepath = os.path.join(pdf_folder, filename)\n",
        "                print(f\"Extrayendo texto de: {filename}\")\n",
        "                try:\n",
        "                    with pdfplumber.open(filepath) as pdf:\n",
        "                        text_id = re.split(\"_\", filename)[1].split(\".\")[0]\n",
        "                        \n",
        "                        all_text = []\n",
        "                        for page in pdf.pages:\n",
        "                            text = page.extract_text()\n",
        "                            if text: # Asegurarse de que se extrajo algo de texto\n",
        "                                all_text.append(text)\n",
        "                    \n",
        "                        unified_text = \"\\n\".join(all_text)    \n",
        "                        \n",
        "                         # Guardar el texto unificado en un archivo .txt\n",
        "                        with open(f\"{output_name_root}_{text_id}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "                            f.write(unified_text)\n",
        "                            \n",
        "                        print(f\"\\nTexto de {len(os.listdir(pdf_folder))} PDFs extra√≠do y guardado en '{output_name_root}_{text_id}'\")\n",
        "                        self.txt_convs[text_id] = unified_text\n",
        "                        \n",
        "                except Exception as e:\n",
        "                    print(f\"Error al procesar {filename}: {e}\")\n",
        "                    \n",
        "    def get_txt(self, num_conv, txt_folder_path):\n",
        "        \n",
        "        filename = \"Texto_convocatoria_{}.txt\".format(num_conv)\n",
        "        if filename in os.listdir(txt_folder_path):\n",
        "            p = os.path.join(txt_folder_path, filename)\n",
        "            with open(p, encoding=\"utf-8\") as f: \n",
        "                return f.read()\n",
        "        \n",
        "        else: \n",
        "            print(f\"El archivo {filename} no est√° en la carpeta.\")\n",
        "        \n",
        "\n",
        "        \n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_url = \"https://www.infosubvenciones.es/bdnstrans/api/convocatorias\"\n",
        "params = {\n",
        "    \"vpd\": \"GE\"        # Cambia por el portal que te interese\n",
        "}\n",
        "headers = {\"Accept\": \"application/json\"}\n",
        "\n",
        "# Iniciar clase\n",
        "get_convs = get_convocatorias(param_grid=params, url=base_url, headers_grid=headers)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-9HTzdiXG6B",
        "outputId": "1957f24e-8203-4477-e32e-d2508601f75b"
      },
      "outputs": [],
      "source": [
        "# Obtener las convocatorias desde la API\n",
        "conv_dict = {}\n",
        "for conv in [\"842695\", \"1051435\"]:  \n",
        "    conv_doc = get_convs.request_convocatorias(conv)\n",
        "    conv_dict[conv] = conv_doc\n",
        "    \n",
        "# Eliminar convocatorias err√≥neas\n",
        "conv_dict = {key: value for key, value in conv_dict.items() if not conv_dict[key].empty}\n",
        "conv_dict.keys()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTKPoniOXnZF"
      },
      "outputs": [],
      "source": [
        "# Guardar las convocatorias en un archivo Excel\n",
        "for k, v in conv_dict.items(): \n",
        "    \n",
        "    if conv_dict[k].empty:\n",
        "        conv = v\n",
        "        convocatoria_file = \"convocatoria_{}.xlsx\".format(k)\n",
        "        print(k)\n",
        "        v.to_excel(convocatoria_file, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filtrar solo el campo de inter√©s para descargar las convocatorias\n",
        "docs = []\n",
        "for doc in conv_dict.values():\n",
        "   docs.append(doc[\"documentos\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Descargar convocatorias\n",
        "get_convs.download_convocatorias(\"documentos_convocatoria\", docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdf_folder = \"documentos_convocatoria\"\n",
        "out_put_txt_file = \"Texto_convocatoria\"\n",
        "\n",
        "get_convs.pdf_to_txt(pdf_folder=pdf_folder, output_name_root=out_put_txt_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0WEnJHSZxLQ",
        "outputId": "fbaa2901-1786-422c-e1fc-70f5152d91b1"
      },
      "outputs": [],
      "source": [
        "# pdf_folder = \"documentos_convocatoria\" # Aseg√∫rate de que esta carpeta exista y contenga tus PDFs\n",
        "# output_txt_file = \"TextoConvocatoria.txt\" # El archivo de texto unificado\n",
        "\n",
        "# all_text = []\n",
        "\n",
        "# # Recorrer todos los archivos en la carpeta de PDFs\n",
        "# for filename in os.listdir(pdf_folder):\n",
        "#     if filename.endswith(\".pdf\"):\n",
        "#         filepath = os.path.join(pdf_folder, filename)\n",
        "#         print(f\"Extrayendo texto de: {filename}\")\n",
        "#         try:\n",
        "#             with pdfplumber.open(filepath) as pdf:\n",
        "#                 for page in pdf.pages:\n",
        "#                     text = page.extract_text()\n",
        "#                     if text: # Asegurarse de que se extrajo algo de texto\n",
        "#                         all_text.append(text)\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error al procesar {filename}: {e}\")\n",
        "\n",
        "# # Unir todo el texto extra√≠do en una sola cadena\n",
        "# unified_text = \"\\n\".join(all_text)\n",
        "\n",
        "# # Guardar el texto unificado en un archivo .txt\n",
        "# with open(output_txt_file, \"w\", encoding=\"utf-8\") as f:\n",
        "#     f.write(unified_text)\n",
        "\n",
        "# print(f\"\\nTexto de {len(os.listdir(pdf_folder))} PDFs extra√≠do y guardado en '{output_txt_file}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unified_text = get_convs.txt_convs[\"1286483\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khI3l_iHap3y",
        "outputId": "afd64e01-e2d5-4550-e90e-b4c7bbb3ec3b"
      },
      "outputs": [],
      "source": [
        "# Dividir en chunks para RAG\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_text(unified_text)\n",
        "print(f\"Texto dividido en {len(texts)} chunks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_x2Xiqb37JE6"
      },
      "outputs": [],
      "source": [
        "api_key = \":)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM8pyaSj7H1J"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sdcgab077TAd"
      },
      "outputs": [],
      "source": [
        "#user_query = \"¬øQu√© ocurre con el Alojamiento, manutenci√≥n y comidas colectivas?\"\n",
        "user_query = \"¬øDe qu√© trata este documento?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbfJcHtX7zWB"
      },
      "outputs": [],
      "source": [
        "# 2. Crear embeddings\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=api_key)\n",
        "vectorstore = FAISS.from_texts(texts, embedding_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf0pwvzd96Pd",
        "outputId": "1a596222-8e71-4b16-b961-777c7230dfe5"
      },
      "outputs": [],
      "source": [
        "# 3. Buscar contexto relevante\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "relevant_docs = retriever.get_relevant_documents(user_query)\n",
        "\n",
        "# 4. Concatenar el contexto\n",
        "context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
        "user_query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir prompt\n",
        "prompt = \"\"\"\n",
        "\n",
        "Eres un asistente experto en ayudas p√∫blicas en Espa√±a. Responde en tono claro y amigable, basado √∫nicamente en el contexto que se te proporciona. \n",
        "Si no encuentras la respuesta a la consulta en el documento, debes decir que no has podido encontrar la informaci√≥n relevante e invitar \n",
        "al usuario a que revise el documento.\n",
        "\n",
        "Si el usuario te pide un resumen del documento, proporciona una respuesta clara y en lenguaje simple del contenido del documento. Indica al usuario el mensaje principal del documento y si se trata de alguna subvenci√≥n o ayuda a la que pueda aplicar. En caso de que no, \n",
        "debes indicar que este documento no tiene ning√∫n informaci√≥n sobre ayudas o subvenciones. Si el documento incluye informaci√≥n de ayudas, haz un resumen\n",
        "de los requisitos que se deben cumplir para acceder a la ayuda e indica al usuario el t√≠tulo de la secci√≥n en la que puede encontrar la informaci√≥n detallada sobre\n",
        "c√≥mo aplicar a la ayuda, si ese t√≠tulo existe. \n",
        "\n",
        "Si el usuario te pide informaci√≥n sobre c√≥mo aplicar a la ayuda descrita en el documento, haz un resumen de los requisitos de aplicaci√≥n indicados en el documento e ind√≠cale la p√°gina o la secci√≥n del documento en donde puede encontrar toda la informaci√≥n sobre los requisitos de aplicaci√≥n. \n",
        "\n",
        "Si el usuario te pregunta si la convocatoria le puede ayudar o servir, pregunta sobre su edad, ocupaci√≥n o profesi√≥n y lugar de residencia en Espa√±a. Ind√≠cale si la convocatoria se ajusta al usuario en funci√≥n de esa informaci√≥n. Nunca digas que la convocatoria no se ajusta. M√°s bien, especifica a qui√©n va dirigida la convocatoria\n",
        "seg√∫n los requisitos en el documento e inv√≠tale a revisarlos para que eval√∫e si se ajustan a sus necesidades. \n",
        "\n",
        "Nunca des informaci√≥n que no encuentres en el documento. Si hay algo que no encuentras, debes decir al usuario que no has encontrado esa informaci√≥n en el documento e invitarle a que lo revise por su propia cuenta. \n",
        "\n",
        " \n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjlxtOk5-wwt",
        "outputId": "54207037-bbb8-4c6c-efb2-a5f1bf0d9778"
      },
      "outputs": [],
      "source": [
        "# 5. Llamar a GPT-4o-mini con contexto manual\n",
        "client = OpenAI(api_key=api_key)\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": f\"Contexto:\\n{context}\\n\\nPregunta:\\n{user_query}\"},\n",
        "        {\"role\": \"system\", \"content\": prompt}    \n",
        "    ],\n",
        "    temperature=0.3,\n",
        "    max_tokens=600  # Limitamos la salida del modelo a 100 tokens para probar como funciona. En el futuro habr√° que deslimitalo\n",
        "\n",
        ")\n",
        "\n",
        "print(\"\\nüß† Respuesta:\")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tX3qCihBBrQe"
      },
      "outputs": [],
      "source": [
        "def responder_pregunta(query, prompt=prompt, k=3, max_tokens=600):\n",
        "    # Buscar contexto relevante\n",
        "    docs = vectorstore.similarity_search(query, k=k)\n",
        "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "    # Llamar a GPT-4o-mini con contexto\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": prompt},\n",
        "            {\"role\": \"user\", \"content\": f\"Contexto:\\n{context}\\n\\nPregunta:\\n{query}\"}\n",
        "        ],\n",
        "        temperature=0.3,\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "\n",
        "    # Mostrar respuesta\n",
        "    print(\"\\nüß† Respuesta:\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "    # Mostrar documentos fuente\n",
        "    # print(\"\\nüìÑ Fuentes:\")\n",
        "    # for doc in docs:\n",
        "    #     print(f\"- Fuente: {doc.metadata.get('source', 'Desconocida')}\")\n",
        "    #     print(f\"  Fragmento:\\n{doc.page_content[:250]}...\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTbEvfhbB-Ks",
        "outputId": "109e85d3-2c88-434a-c488-15c8e9838608"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "    user_query = input(\"\\n‚ùì Escribe tu pregunta (o 'salir'): \")\n",
        "    if user_query.lower() in [\"salir\", \"exit\", \"quit\"]:\n",
        "        break\n",
        "    responder_pregunta(user_query)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
